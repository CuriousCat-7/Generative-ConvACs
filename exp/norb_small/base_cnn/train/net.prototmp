{% macro input(name, path, batch_size, is_train, shuffle=True, is_2d=True, stage=None) %}
   layer {
        name: "{{ name }}_labeled"
        type: "ImageData"
        top: "raw_data"
        top: "label"
        image_data_param {
            source: "data/{{ path }}/index.txt"
            root_folder: "data/{{ path }}/"
            batch_size: {{ batch_size | int }}
            shuffle: {{ shuffle }}
            is_color: {{ true if is_2d else false}}
        }
        transform_param {
          scale: 0.00390625
        }
        include: { 
            phase: {{ 'TRAIN' if is_train else 'TEST' }}
            {{ ('stage: "%s"' | format(stage)) if stage }}
        }
    }
{% endmacro %}



{% macro conv(name, bottom, top, num_kernels, kernel_size, w_std=0, pad=0, w_lr=1, b_lr=2, stride=1, stage = None, phase = None) %}
layer {
  name: "{{ name }}"
  type: "Convolution"
  bottom: "{{ bottom }}"
  top: "{{ top }}"
  param {
    lr_mult: {{ w_lr }}
  }
  param {
    lr_mult: {{ b_lr }}
  }
  convolution_param {
    num_output: {{ num_kernels | int }}
    kernel_size: {{ kernel_size | int }}
    stride: {{ stride | int}}
    pad: {{ pad | int }}
    weight_filler {
      {% if w_std > 0 %}
      type: "gaussian"
      std: {{ w_std }}
      {% else %}
      type: "xavier"
      {% endif %}
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }

  {% if phase %}

  include: { 
            phase: {{ phase }}
            {{ ('stage: "%s"' | format(stage)) if stage }}
        }
    
  {% endif %}

  
}
{% endmacro %}
{% macro pool(name, bottom, top, kernel_size=2, stride=2, pad=0, pool_function='MAX') %}
layer {
  name: "{{ name }}"
  type: "Pooling"
  bottom: "{{ bottom }}"
  top: "{{ top }}"
  pooling_param {
    pool: {{ pool_function }}
    kernel_size: {{ kernel_size | int }}
    stride: {{ stride | int }}
    pad: {{ pad | int }}
    engine: CUDNN
  }
}
{% endmacro %}
{% macro relu(name, bottom, top=None, neg_slope = 0.001) %}
layer {
  name: "{{ name }}"
  type: "ReLU"
  bottom: "{{ bottom }}"
  top: "{{ top if top != None else bottom }}"
  relu_param {
    negative_slope: {{ neg_slope }}
    engine: CUDNN
  }
}
{% endmacro %}
{% macro dropout(name, bottom, top, prob=0.5) %}
layer {
  name: "{{ name }}"
  type: "Dropout"
  bottom: "{{ bottom }}"
  top: "{{ top }}"
  dropout_param {
     dropout_ratio: {{ prob }}
  }
}
{% endmacro %}


{% macro ip_layer(name, bottom, top, num_outputs, w_lr=1, b_lr=2, shared_suffix='',frozen=False, w_std=0.01) %}

layer {
  name: "{{ name ~ shared_suffix }}"
  type: "InnerProduct"
  bottom: "{{ bottom ~ shared_suffix }}"
  top: "{{ top ~ shared_suffix }}"
  param {
    lr_mult: {{ w_lr }}
  }
  param {

    lr_mult: {{ b_lr }}

  }
  inner_product_param {
    num_output: {{ num_outputs }}
    weight_filler {
      type: "gaussian"
      std: {{ w_std }}
      
    }
    bias_filler {
      type: "constant"
    }

  }
}

{% endmacro %}



# Number of iterations between tests
test_interval: 1000
# Covering the full 24,300 sample testing and 12k sample subset of augmented training set.
test_iter: 405
test_state: { stage: "test-on-test-set" }
test_iter: 200
test_state: { stage: "test-on-train-set" }
# The base learning rate, momentum and the weight decay of the network.
base_lr: {{ base_lr }}
momentum: {{ momentum }}
weight_decay: {{ weight_decay }}
# The learning rate policy

lr_policy: "multistep"
gamma: {{ gamma }}
stepvalue: {{ (max_iter * 0.75) | int }}
step_lr: {{ base_lr }}
step_policy: "linear"
stepvalue: {{ (max_iter * 0.9) | int }}
step_lr: {{ base_lr*0.1 }}
step_policy: "linear"

stepvalue: {{ max_iter | int }}
step_lr: {{ 0 }}
step_policy: "linear"

# Number of iterations between displays
display: 20
# The maximum number of iterations
max_iter: {{ max_iter | int }}
# snapshot intermediate results
snapshot: 10000
snapshot_prefix: "{{ name }}"
# solver mode: CPU or GPU
solver_mode: GPU
type: "{{ solver_type }}"
debug_info: false
random_seed: {{ caffe_random_seed }}

net_param {
    name: "{{ name }}"
    ##############
    ### Source ###
    ##############
    {{ input('norb_train', 'aug_norb_small_2D_whole_train_image_data', labeled_batch, is_train=True, is_2d=True, shuffle=True) }}
    {{ input('norb_test', 'norb_small_2D_test_image_data', 60, is_train=False, is_2d=True, shuffle=False, stage='test-on-test-set') }}
    {{ input('norb_train-test', 'aug_norb_small_2D_whole_train_image_data', 60, is_train=False, is_2d=True, shuffle=True, stage='test-on-train-set') }}
    

  # Slice the image to obtain the 2 channels with the binocular image data in 
  # first 2 channels (R,G). Since Caffe reads images in BGR order we want the last
  # two channels loaded by the ImageData layer.
  layer {
        name: "slice_data"
        type: "Slice"
        bottom: "raw_data"
        top: "junk_channel"
        top: "data"
        slice_param {

        	axis: 1
        	slice_point: 1
        }

    }

   layer {
        name: "slice_data_silence"
        type: "Silence"
        bottom: "junk_channel"
    }

    ###############
    ### Layer 1 ###
    ###############


{{ conv('conv_1', 'data', 'conv_1', num_kernels=conv_1_num_kernels, kernel_size=5, w_std=weights1_std, pad=2, w_lr=1, b_lr=2, stride=1) }}
{{ pool('pool_1', 'conv_1', 'pool_1', kernel_size=3, stride=2,pad=0, pool_function='MAX') }}
{{ relu('relu_pool_1', 'pool_1', 'pool_1', neg_slope=0) }}
{{ dropout('drop1', 'pool_1', 'pool_1', drop1_prob) }}

{{ conv('conv_2', 'pool_1', 'conv_2', num_kernels=conv_2_num_kernels, kernel_size=5, w_std=weights2_std, pad=2, w_lr=1, b_lr=2, stride=1) }}
{{ relu('relu_conv_2', 'conv_2', 'conv_2', neg_slope=0) }}
{{ dropout('drop2', 'conv_2', 'conv_2', drop2_prob) }}
{{ pool('pool_2', 'conv_2', 'pool_2', kernel_size=3, stride=2,pad=0, pool_function='AVE') }}


{{ conv('conv_3', 'pool_2', 'conv_3', num_kernels=conv_3_num_kernels, kernel_size=5, w_std=weights3_std, pad=2, w_lr=1, b_lr=2, stride=1) }}
{{ relu('relu_conv_3', 'conv_3', 'conv_3', neg_slope=0) }}
{{ dropout('drop3', 'conv_3', 'conv_3', drop3_prob) }}
{{ pool('pool_3', 'conv_3', 'pool_3', kernel_size=3, stride=2,pad=0, pool_function='AVE') }}

{{ ip_layer('fc_1', 'pool_3', 'fc_1', num_outputs=768, w_lr=1, b_lr=2, shared_suffix='',frozen=False, w_std=fc_w_std) }}
{{ relu('relu_fc_1', 'fc_1', 'fc_1', neg_slope=0) }}
{{ dropout('drop4', 'fc_1', 'fc_1', drop4_prob) }}

{{ ip_layer('fc_final', 'fc_1', 'fc_final', num_outputs=5, w_lr=1, b_lr=2, shared_suffix='',frozen=False, w_std=fc2_w_std) }}


layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc_final"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc_final"
  bottom: "label"
  top: "loss"
  softmax_param {
    engine: CUDNN
  }
}

}
